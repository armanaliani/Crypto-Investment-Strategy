{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600f80cd-f3d0-4f3e-9ee4-cab5ba39c920",
   "metadata": {},
   "source": [
    "# Discord Scrape\n",
    "#### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a658e79-ac4b-45f2-9cea-9accd6f179b7",
   "metadata": {},
   "source": [
    "To begin our data collection process, we will be getting data from a private discord server. \n",
    "\n",
    "Each message in this channel has token metrics for the moment that liquidity has been locked in for the token and trading is live. In a real world setting, this is all the information we know when guaging whether a token is a good investment or not.\n",
    "\n",
    "This data includes:\n",
    "\n",
    "- Token address\n",
    "- Contract creation date\n",
    "- Verified/Renounced status of contract\n",
    "- Marketcap\n",
    "- Number of Buys and Sells\n",
    "- Honeypot status (a common scam)\n",
    "- Tax information\n",
    "- Liquidity\n",
    "- Owner (Where liquidity tokens have been locked)\n",
    "- Unlock date (if any)\n",
    "- Holder contract link\n",
    "- Deployer contract link\n",
    "- Funding source link\n",
    "- amount of ethereum held in contracts\n",
    "- maximum number of tokens allowed per transaction and per wallet\n",
    "- Liquidity time (from message timestamp)\n",
    "- Description\n",
    "- Social meda links\n",
    "- Contract links\n",
    "\n",
    "For our immediate purposes, we will focus on numeric data, links will be ignored.\n",
    "\n",
    "There have been updates to the structure of the alert messages as the team of the product have updated the metrics available over the years. For consistency in our data we will be starting our scrape from the first message id that contains our desired structure. \n",
    "\n",
    "There are also some limitations to keep in mind:\n",
    "- 50 messages per request\n",
    "- 50 requests per second\n",
    "\n",
    "More information on interacting with discords api as it pertains to this project can be found here:\n",
    "- https://discord.com/developers/docs/resources/channel#get-channel-messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ebd2e0-94b8-4eaf-9507-d4a1250a8a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the end of available messages.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def retrieve_msgs(channel_id, after_id='000000000000', output_file='../data/unique_scraped_data_alert_time.json'):\n",
    "    headers = {\n",
    "        'authorization': #api key here\n",
    "    }\n",
    "\n",
    "    url = f'https://discord.com/api/v9/channels/{channel_id}/messages'\n",
    "    params = {'after': after_id}\n",
    "\n",
    "    existing_data = set()  # Store existing 'dict0' values to check for duplicates\n",
    "    \n",
    "    with open(output_file, 'a') as file:\n",
    "        while True:\n",
    "            req = requests.get(url, headers=headers, params=params)\n",
    "            if req.status_code == 200:\n",
    "                json_data = req.json()\n",
    "                \n",
    "                if not json_data:\n",
    "                    print(\"Reached the end of available messages.\")\n",
    "                    break\n",
    "                \n",
    "                for msg in json_data:\n",
    "                    if 'embeds' in msg and msg['embeds']:\n",
    "                        scraped_item_data = {'dict0': msg['embeds'][0]['description'][-43:-1]}\n",
    "                        skip_values = {9, 10, 11, 18, 19, 20, 25}\n",
    "\n",
    "                        for f, field in enumerate(msg['embeds'][0]['fields'], 1):\n",
    "                            if f not in skip_values:\n",
    "                                scraped_item_data[f'dict{f}'] = field\n",
    "\n",
    "                        scraped_item_data['timestamp'] = msg['timestamp']\n",
    "                        \n",
    "                        # Check for duplicate 'dict0' values before writing\n",
    "                        dict0_value = scraped_item_data['dict0']\n",
    "                        if dict0_value not in existing_data:\n",
    "                            json.dump(scraped_item_data, file)\n",
    "                            file.write('\\n')\n",
    "                            existing_data.add(dict0_value)  # Add 'dict0' value to the set of existing data\n",
    "\n",
    "                last_message_id = json_data[-1]['id']\n",
    "                params['after'] = last_message_id\n",
    "                time.sleep(1)  # Delay in seconds between API calls, conservatively within rate limit as this is my main account\n",
    "\n",
    "            else:\n",
    "                print(f'Error: {req.status_code} - {req.text}')\n",
    "                break\n",
    "\n",
    "liq_lock = # channel id\n",
    "retrieve_msgs(liq_lock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a926a702-8e59-4a73-b2e5-0dfe48a75603",
   "metadata": {},
   "source": [
    "Testing json file readability to see if data looks how we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1961cf75-0215-4943-82a9-0fbfa1b28928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last JSON object: {'dict0': '0xf893f20cf0f3cf47cb8ba2f45995b92d46a19e2f', 'dict1': {'name': 'Created', 'value': '<t:1674241739:R>', 'inline': True}, 'dict2': {'name': 'Verified | Renounced', 'value': ':green_circle: True | :green_circle: Not Ownable', 'inline': True}, 'dict3': {'name': 'Marketcap', 'value': '$7,956', 'inline': True}, 'dict4': {'name': 'Buys | Sells', 'value': ':red_circle: 14 | 0', 'inline': True}, 'dict5': {'name': 'Honeypot', 'value': ':green_circle: Buy | :green_circle: Sell', 'inline': True}, 'dict6': {'name': 'Taxes', 'value': ':green_circle: 5% | 5.9%', 'inline': True}, 'dict7': {'name': 'Liquidity', 'value': ':green_circle: $12,541', 'inline': True}, 'dict8': {'name': 'Owner', 'value': ':red_circle: 100% Pinksale', 'inline': True}, 'dict12': {'name': 'Eth Balance', 'value': '-\\n0.04Ξ\\n0.28Ξ\\n5.83Ξ\\n0.02Ξ\\n0.06Ξ\\n0.08Ξ\\n0.15Ξ\\n-', 'inline': True}, 'dict13': {'name': 'Deployer', 'value': '[0xc83e…698e](https://etherscan.io/address/0xc83e6f1cc56892cf7de3550645bbeb4a5352698e)', 'inline': True}, 'dict14': {'name': 'Balance', 'value': '1.19Ξ', 'inline': True}, 'dict15': {'name': 'Tx Count', 'value': '23', 'inline': True}, 'dict16': {'name': 'Funding Sources', 'value': ':green_circle: [Binance 20](https://etherscan.io/address/0x4976a4a02f38326660d17bf34b431dc6e2eb2327)', 'inline': True}, 'dict17': {'name': 'Amount', 'value': '4.10Ξ', 'inline': True}, 'dict21': {'name': 'Date', 'value': '<t:1673701199:R>', 'inline': True}, 'dict22': {'name': 'Max Wallet', 'value': '-', 'inline': True}, 'dict23': {'name': 'Max TX', 'value': '-', 'inline': True}, 'dict24': {'name': 'Links', 'value': '[DexTools](https://www.dextools.io/app/ether/pair-explorer/0x99e6953fb248c9912c3d566d553fea7dcb1ca587) · [DexScreener](https://dexscreener.com/ethereum/0x99e6953fb248c9912c3d566d553fea7dcb1ca587) · [CoinScan](https://www.coinscan.com/tokens/0x99e6953fb248c9912c3d566d553fea7dcb1ca587) · [LP Etherscan](https://etherscan.io/token/0x99e6953fb248c9912c3d566d553fea7dcb1ca587) · [Search Twitter](https://twitter.com/search?q=%24KRAKEN&f=live)\\n**Contract Links**\\n-', 'inline': False}, 'timestamp': '2023-01-20T21:06:27.197000+00:00'}\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/unique_scraped_data_alert_time.json'\n",
    "\n",
    "# Initialize a list to store individual JSON objects\n",
    "json_objects = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    # Read each line in the file\n",
    "    for line in file:\n",
    "        # Load each line as a JSON object\n",
    "        try:\n",
    "            json_obj = json.loads(line)\n",
    "            json_objects.append(json_obj)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "# Check if JSON objects were found\n",
    "if json_objects:\n",
    "    # Access the last JSON object in the list\n",
    "    last_json_object = json_objects[-1]\n",
    "    print(\"Last JSON object:\", last_json_object)\n",
    "else:\n",
    "    print(\"No valid JSON objects found in the file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099af348-2f82-4a15-be7a-a1019c004af4",
   "metadata": {},
   "source": [
    "Next, we will transform this json data into a pandas dataframe in: **['discord_dataframe_step_2'](./discord_dataframe_step_2.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fdcfaf-e731-4089-a448-60fa1e99f143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
